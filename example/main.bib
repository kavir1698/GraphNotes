@InCollection{sep-logic-information,
	author       =	{Martinez, Maricarmen and Sequoiah-Grayson, Sebastian},
	title        =	{Logic and Information},
	booktitle    =	{The Stanford Encyclopedia of Philosophy},
	editor       =	{Edward N. Zalta},
	howpublished =	{\url{https://plato.stanford.edu/archives/win2016/entries/logic-information/}},
	year         =	{2016},
	edition      =	{Winter 2016},
	publisher    =	{Metaphysics Research Lab, Stanford University}
}
@book{Floridi2011,
address = {Oxford, UK},
annote = {Anattempt to comprehend the philosophy of information as
 first philosophy
and use it as such toaddress several unresolved philosophical problems},
author = {Floridi, Luciano},
isbn = {0199232393},
publisher = {Oxford University Press},
title = {{The Philosophy of Information}},
year = {2011}
}
@article{ClaudeShannon1948,
author = {{Claude Shannon} and Shannon, CE},
journal = {Bell System Technical Journal},
pages = {379--423},
title = {{A Mathematical Theory of Communication}},
volume = {27},
year = {1948}
}
@article{Rzhetsky2015,
abstract = {A scientist's choice of research problem affects his or her personal career trajectory. Scientists' combined choices affect the direction and efficiency of scientific discovery as a whole. In this paper, we infer preferences that shape problem selection from patterns of published findings and then quantify their efficiency. We represent research problems as links between scientific entities in a knowledge network. We then build a generative model of discovery informed by qualitative research on scientific problem selection. We map salient features from this literature to key network properties: an entity's importance corresponds to its degree centrality, and a problem's difficulty corresponds to the network distance it spans. Drawing on millions of papers and patents published over 30 years, we use this model to infer the typical research strategy used to explore chemical relationships in biomedicine. This strategy generates conservative research choices focused on building up knowledge around important molecules. These choices become more conservative over time. The observed strategy is efficient for initial exploration of the network and supports scientific careers that require steady output, but is inefficient for science as a whole. Through supercomputer experiments on a sample of the network, we study thousands of alternatives and identify strategies much more efficient at exploring mature knowledge networks. We find that increased risk-taking and the publication of experimental failures would substantially improve the speed of discovery. We consider institutional shifts in grant making, evaluation, and publication that would help realize these efficiencies.},
archivePrefix = {arXiv},
arxivId = {arXiv:1408.1149},
author = {Rzhetsky, Andrey and Foster, Jacob G and Foster, Ian T. and Evans, James a.},
doi = {10.1073/pnas.1509757112},
eprint = {arXiv:1408.1149},
file = {:C$\backslash$:/Users/arvka/Dropbox/Papers/Rzhetsky et al/Proceedings of the National Academy of Sciences of the United States of America{\_}2015{\_}Choosing experiments to accelerate collective disco.pdf:pdf},
isbn = {1509757112},
issn = {1091-6490},
journal = {Proceedings of the National Academy of Sciences of the United States of America},
keywords = {complex networks,computational biology,innovation,science of science,sociology of science},
month = {nov},
number = {47},
pages = {14569--74},
pmid = {26554009},
title = {{Choosing experiments to accelerate collective discovery.}},
url = {http://www.pnas.org/content/early/2015/11/04/1509757112.abstract.html?etoc http://www.ncbi.nlm.nih.gov/pubmed/26554009 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4664375},
volume = {112},
year = {2015}
}
@article{Beavers2011,
author = {Beavers, Anthony F},
file = {:C$\backslash$:/Users/arvka/Dropbox/Papers/Beavers/Unknown{\_}2011{\_}A Brief Introduction to the Philosophy of Information.pdf:pdf},
number = {2011},
pages = {1--11},
title = {{A Brief Introduction to the Philosophy of Information}},
year = {2011}
}
@article{Higginson2016,
author = {Higginson, Andrew D. and Munaf{\`{o}}, Marcus R.},
doi = {10.1371/journal.pbio.2000995},
file = {:C$\backslash$:/Users/arvka/Dropbox/Papers/Higginson, Munaf{\`{o}}/PLOS Biology{\_}2016{\_}Current Incentives for Scientists Lead to Underpowered Studies with Erroneous Conclusions.pdf:pdf},
issn = {1545-7885},
journal = {PLOS Biology},
month = {nov},
number = {11},
pages = {e2000995},
title = {{Current Incentives for Scientists Lead to Underpowered Studies with Erroneous Conclusions}},
url = {http://dx.plos.org/10.1371/journal.pbio.2000995},
volume = {14},
year = {2016}
}
@article{Smaldino2016,
abstract = {Poor research design and data analysis encourage false-positive findings. Such poor methods persist despite perennial calls for improvement, suggesting that they result from something more than just misunderstanding. The persistence of poor methods results partly from incentives that favor them, leading to the natural selection of bad science. This dynamic requires no conscious strategizing—no deliberate cheating nor loafing—by scientists, only that publication is a principle factor for career advancement. Some normative methods of analysis have almost certainly been selected to further publication instead of discovery. In order to improve the culture of science, a shift must be made away from correcting misunderstandings and towards rewarding understanding. We support this argument with empirical evidence and computational modeling. We first present a 60-year meta-analysis of statistical power in the behavioral sciences and show that power has not improved despite repeated demonstrations of the necessity of increasing power. To demonstrate the logical consequences of structural incentives, we then present a dynamic model of scientific communities in which competing laboratories investigate novel or previously published hypotheses using culturally transmitted research methods. As in the real world, successful labs produce more “progeny,” such that their methods are more often copied and their students are more likely to start labs of their own. Selection for high output leads to poorer methods and increasingly high false discovery rates. We additionally show that replication slows but does not stop the process of methodological deterioration. Improving the quality of research requires change at the institutional level.},
archivePrefix = {arXiv},
arxivId = {arXiv:1605.09511v1},
author = {Smaldino, PAUL E. and McElreath, Richard},
doi = {10.1098/rsos.160384},
eprint = {arXiv:1605.09511v1},
file = {:C$\backslash$:/Users/arvka/Dropbox/Papers/Smaldino, McElreath/Royal Society Open Science{\_}2016{\_}The natural selection of bad science.pdf:pdf},
issn = {2054-5703},
journal = {Royal Society Open Science},
keywords = {computer modelling,theoretical biology},
month = {sep},
number = {9},
pages = {160384},
title = {{The natural selection of bad science}},
url = {http://rsos.royalsocietypublishing.org/lookup/doi/10.1098/rsos.160384},
volume = {3},
year = {2016}
}
@article{Allo2007,
author = {Allo, Patrick},
file = {:home/alirv/Dropbox/Papers/Allo/Workshop on Logic and Philosophy of Knowledge, Communication and Action{\_}2007{\_}Informational Content and Information Structures a Pluralis.pdf:pdf},
journal = {Workshop on Logic and Philosophy of Knowledge, Communication and Action},
keywords = {C1},
mendeley-groups = {Information theory},
number = {2006},
pages = {101--121},
title = {{Informational Content and Information Structures: a Pluralist Approach}},
year = {2007}
}
@book{Floridi2010,
address = {Oxford ; New York},
author = {Floridi, Luciano},
isbn = {9780199551378},
mendeley-groups = {Information theory},
publisher = {Oxford University Press},
title = {{Information : a very short introduction}},
year = {2010}
}
@article{Uzzi2018,
author = {Fortunato, Santo and Bergstrom, Carl T. and B{\"{o}}rner, Katy and Evans, James A. and Helbing, Dirk and Milojevi{\'{c}}, Sta{\v{s}}a and Petersen, Alexander M. and Radicchi, Filippo and Sinatra, Roberta and Uzzi, Brian and Vespignani, Alessandro and Waltman, Ludo and Wang, Dashun and Barab{\'{a}}si, Albert-L{\'{a}}szl{\'{o}}},
doi = {10.1126/science.aao0185},
file = {:home/alirv/Dropbox/Papers/Uzzi et al/Science{\_}2018{\_}Science of science.pdf:pdf},
issn = {0036-8075},
journal = {Science},
mendeley-groups = {scientometrics},
month = {mar},
number = {6379},
pages = {eaao0185},
title = {{Science of science}},
url = {http://www.sciencemag.org/lookup/doi/10.1126/science.aao0185},
volume = {359},
year = {2018}
}
@article{Wu2019,
archivePrefix = {arXiv},
arxivId = {10.1038/s41586-019-0941-9},
author = {Wu, Lingfei and Wang, Dashun and Evans, James A.},
doi = {10.1038/s41586-019-0941-9},
eprint = {s41586-019-0941-9},
isbn = {9780309085120},
issn = {1476-4687},
journal = {Nature},
mendeley-groups = {science metrics},
month = {feb},
number = {7744},
pages = {378--382},
pmid = {30760923},
primaryClass = {10.1038},
publisher = {Springer US},
title = {{Large teams develop and small teams disrupt science and technology}},
url = {http://www.nature.com/articles/s41586-019-0941-9 http://www.ncbi.nlm.nih.gov/pubmed/30760923},
volume = {566},
year = {2019}
}
@book{Price1963,
address = {New York},
author = {Price, Derek J. de Solla},
mendeley-groups = {scientometrics},
publisher = {Columbia University Press},
title = {{Little science, big science}},
year = {1963}
}
@article{Milojevic2015,
archivePrefix = {arXiv},
arxivId = {1511.00040},
author = {Milojevi{\'{c}}, Sta{\v{s}}a},
doi = {10.1016/j.joi.2015.10.005},
eprint = {1511.00040},
issn = {17511577},
journal = {Journal of Informetrics},
keywords = {Big science,Cognitive extent,Collaboration,Growth of science,Team science},
mendeley-groups = {scientometrics},
month = {oct},
number = {4},
pages = {962--973},
title = {{Quantifying the cognitive extent of science}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S175115771530081X},
volume = {9},
year = {2015}
}
